**问题描述**
- 所有用户访问APP响应时间非常慢。
- 进行FACE ID身份证以及活体验证会出现图片上传失败问题。
- 信审后台订单列表页无法正常快速显示。

**MongoDB CPU数据呈现**

- 2018年5月30号，从早上11：00到晚上23：00持续12h的系统慢。

**从图中可以看到在该时间段内，MongoDB的CPU保持在一个较高的水平线上。**

![](http://p9xzf2pi2.bkt.clouddn.com/18-6-7/68664159.jpg)


<!-- ![](http://p9xzf2pi2.bkt.clouddn.com/18-6-7/81809751.jpg) -->

**ELK DB慢查询数据呈现**

![](http://p9xzf2pi2.bkt.clouddn.com/18-6-7/37122151.jpg)

![](http://p9xzf2pi2.bkt.clouddn.com/18-6-7/77504592.jpg)

![](http://p9xzf2pi2.bkt.clouddn.com/18-6-7/74159590.jpg)

**从图中可以看到在该时间段内，MongoDB的某些表都在一个响应时间非常慢的水平上。**

**ELK SQL慢查询数据呈现**

![](http://p9xzf2pi2.bkt.clouddn.com/18-6-7/94259827.jpg)

![](http://p9xzf2pi2.bkt.clouddn.com/18-6-7/15504027.jpg)




**BUG直接原因**

    服务端进行数据查询时SQL写的不好，没有考虑到DB的性能问题，而且没有种上正确的索引甚至连索引都没有，造成慢查询，在多个慢查询叠加的情况下将DB的性能降到谷底，CUP飚高，最终导致所有连接该数据库的服务都是一个响应非常慢甚至无法正常接收请求的地步。

**BUG本质原因**

    1：MongoDB的各个数据库表没有加上正确的索引，查询时没有执行最优解——正确的查询条件、正确的取值以及条数限制，SQL是否是最优的查询语句也没有把控好。
    2：系统缺乏设计，无法承受住10倍乃至100倍的并发量。
    3：不重视对于慢查询的优化。
    4：没有进行压力测试，无法对系统的承受能力有个保守的估计。

**TODO**
    
    1：当系统出现异常现象时，第一时间应该马上查看Grafana | ELK初步定位问题是数据库问题还是程序问题，而不应该一头转进代码中查询细节问题。通过Grafana可以直观看出是哪个接口请求数量明显增高，哪个接口响应时间过长；ELK可以直观看出到底是哪个SQL语句有问题，特别是类型为COLLSCAN并且扫过的文档条数为1W+的case，我们更是要关心对它进行优化，最简单粗暴的解决方法就是给查询条件加上索引（要有意义才行）。
    2：给每个DEV普及查询时的最优解的想法，对于复杂的查询条件时，我们得去思考我们的文档设计的是不是合理，这样的查询方法是不是合理的，严谨使用没有加入索引的字段。
    3：不定时查看Grafana和ELK。
    4：定时对系统进行压测和优化。
    

